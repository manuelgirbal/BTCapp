yearly_transactions <- html_document %>%
html_elements("table") %>%
html_table()
View(yearly_transactions)
html_document %>%
html_elements("table")
html_document
html_document$node
html_document$doc
library(httr)
library(rvest)
# Get the API endpoint for yearly bitcoin transactions
api_endpoint <- "https://blockchain.info/charts/total-bitcoins-sent?timespan=1year"
# Make the API request
api_response <- GET(api_endpoint)
# Get the HTML document
html_document <- read_html(api_response$content)
# Extract the summary of yearly bitcoin transactions
yearly_transactions <- html_document %>%
html_nodes("table") %>%
html_table() %>%
.[[1]]
length(yearly_transactions)
library(tidyverse)
library(httr)
library(jsonlite)
library(lubridate)
# Define the API endpoint URL
url <- "https://mempool.space/api/mempool/txids"
# Send the HTTP request to the API endpoint
response <- GET(url)
# Convert the response to a JSON object
json_data <- fromJSON(content(response, "text"))
json_data
count(json_data)
class(json_data)
unique(json_data)
summarise(n = n(json_data))
nrow(json_data)
ncol(json_data)
size_sum(json_data)
# Define the API endpoint URL
url <- "https://mempool.space/api/block/000000000000000015dc777b3ff2611091336355d3f0ee9766a2cf3be8e4b1ce/txids"
# Send the HTTP request to the API endpoint
response <- GET(url)
# Convert the response to a JSON object
json_data <- fromJSON(content(response, "text"))
json_data
url <- "https://api.blockstream.info/api/v1/blocks/count"
response <- GET(url)
url <- "https://api.blockstream.info/api/blocks/count"
response <- GET(url)
# Define the base URL of the Blockstream Esplora API
base_url <- "https://blockstream.info/api/"
# Function to query Bitcoin transactions from the Esplora API
get_all_bitcoin_transactions <- function() {
endpoint <- "txs"
url <- paste0(base_url, endpoint)
response <- GET(url)
if (http_type(response) != "application/json") {
stop("Error: Failed to fetch data. Please check the API endpoint.")
}
json_data <- fromJSON(content(response, "text"))
return(json_data)
}
# Call the function to get all Bitcoin transactions
bitcoin_transactions <- get_all_bitcoin_transactions()
# Define the base URL of the ....................
base_url <- "https://api.blockchair.com/bitcoin/transactions?s=time(desc)"
# Send the HTTP request to the API endpoint
response <- GET(url)
# Define the base URL of the ....................
url <- "https://api.blockchair.com/bitcoin/transactions?s=time(desc)"
# Send the HTTP request to the API endpoint
response <- GET(url)
# Convert the response to a JSON object
json_data <- fromJSON(content(response, "text"))
json_data$data
# Extract the price data from the JSON object
txs <- json_data$context
View(txs)
View(json_data)
as_tibble(json_data$data)
url <- "https://gz.blockchair.com/bitcoin/transactions/"
response <- GET(url)
data <- content(response, as = "parsed")
View(data)
data <- fromJSON(url)
library(rvest)
url <- "https://gz.blockchair.com/bitcoin/transactions/"
page <- read_html(url)
data <- page %>% html_table()
View(data)
View(page)
url <- "https://gz.blockchair.com/bitcoin/transactions/"
html <- read_html(url)
# Find the line number of the start of the data you want to scrape
start_line <- 34
# Find the end of the data you want to scrape
end_tag <- "</pre><hr></body>"
# Extract the data from the HTML
data <- html %>%
html_nodes(xpath='//pre') %>%
html_text() %>%
str_sub(start_line, nchar(end_tag) - 1)
# Print the data
print(data)
url <- "https://gz.blockchair.com/bitcoin/transactions/"
html <- read_html(url)
# Find the start of the data you want to scrape
start_tag <- "<h1>Index of /bitcoin/transactions/</h1><hr><pre>"
# Find the end of the data you want to scrape
end_tag <- "</pre><hr></body>"
?xpath
?html_nodes
# Extract the data from the HTML
data <- html %>%
html_nodes(xpath='//pre') %>%
html_text() %>%
str_sub(start_tag, nchar(end_tag) - 1)
# Convert the data to a dataset
data <- data.frame(data = strsplit(data, "\n")[[1]])
# Print the data
print(data)
url <- "https://gz.blockchair.com/bitcoin/transactions/"
html <- read_html(url)
# Find the start of the data you want to scrape
start_tag <- "<h1>Index of /bitcoin/transactions/</h1><hr><pre>"
# Find the end of the data you want to scrape
end_tag <- "</pre><hr></body>"
# Extract the data from the HTML
data <- html %>%
html_nodes(xpath='//pre') %>%
html_text() %>%
str_sub(as.character(start_tag), nchar(as.character(end_tag)) - 1)
# Convert the data to a dataset
data <- data.frame(data = strsplit(data, "\n")[[1]])
# Print the data
print(data)
library(tidyverse)
library(rvest)
# Reading "Blockchair Database Dumps" historic bitcoin transactions table:
blockchair <- read_html("https://gz.blockchair.com/bitcoin/transactions/")
# Selecting xpath of the transactions table:
txs <- blockchair %>%
html_element(xpath = "/html/body/pre")
txs
txs %>% html_table()
txs_data <- txs %>%
html_nodes("a") %>%
html_text() %>%
strsplit(" ", simplify = TRUE) %>%
purrr::keep(~ !str_detect(.x, "<"))
txs_data <- txs %>%
html_nodes("a") %>%
html_text() %>%
strsplit(" ") %>%
purrr::keep(~ !str_detect(.x, "<"))
txs_data
class(txs_data)
txs_data <- txs %>%
html_nodes("a") %>%
html_text() %>%
strsplit(" ", simplify = TRUE) %>%
map(~ .[2])
txs_data <- txs %>%
html_nodes("a") %>%
html_text() %>%
strsplit(" ") %>%
map(~ .[2])
txs_data
txs %>%
html_text()
txs %>%
html_text() %>%
strsplit(" ")
?purrr
txs_data <- txs %>%
html_text() %>%
strsplit(" ") %>%
purrr::keep(~ str_detect(.x, "-")) %>%
map(~ .[1])
txs %>%
html_text() %>%
strsplit(" ") %>%
purrr::keep(~ str_detect(.x, "-"))
txs_data <- txs %>%
html_text() %>%
strsplit(" ") %>%
purrr::keep(~ any(str_detect(.x, "-"))) %>%
map(~ .[1])
txs_data
txs %>%
html_text()
txs %>%
html_text() %>%
strsplit(" ")
?keep
txs %>%
html_text() %>%
strsplit(" ") %>%
purrr::keep(~ any(str_detect(.x, "-")))
txs %>%
html_text() %>%
strsplit(" ") %>%
purrr::keep(~ any(str_detect(.x, "-"))) %>%
map(~ .[1])
txs %>%
html_text() %>%
strsplit(" ") %>%
purrr::keep(~(str_detect(.x, "-"))) %>%
map(~ .[1])
txs %>%
html_text() %>%
strsplit(" ")
library(tidyverse)
library(rvest)
# Reading "Blockchair Database Dumps" historic bitcoin transactions table:
blockchair <- read_html("https://gz.blockchair.com/bitcoin/transactions/")
# Selecting xpath of the transactions table:
txs <- blockchair %>%
html_element(xpath = "/html/body/pre")
txs
txs %>%
html_text()
txs %>%
html_text() %>%
strsplit(" ")
txs_data <- txs %>%
html_text() %>%
strsplit(" ")
txs_data
class(txs_data)
txs %>%
html_text()
txs %>%
html_text() %>%
strsplit(" ")
txs %>%
html_text() %>%
strsplit(" ") %>%
unlist()
txs_data <- txs %>%
html_text() %>%
strsplit(" ") %>%
unlist() %>%
keep(grepl("-", .))
txs_data
txs %>%
html_text() %>%
strsplit(" ") %>%
unlist() %>%
keep(grepl("-", .)) %>%
as_tibble()
)) %>%
txs_data <- txs %>%
html_text() %>%
strsplit(" ") %>%
unlist() %>%
keep(grepl("-", .)) %>%
as_tibble()
View(txs_data)
View(txs_data)
View(txs_data)
View(txs_data)
txs_data
# Reading "Blockchair Database Dumps" historic bitcoin transactions table:
blockchair <- read_html("https://gz.blockchair.com/bitcoin/transactions/")
txs <- blockchair %>%
html_element(xpath = "/html/body/pre")
txs
# Selecting xpath of the transactions table:
txs <- blockchair %>%
html_element(xpath = "/html/body/pre") %>%
html_text() %>%
strsplit(" ") %>%
unlist() %>%
keep(grepl("-", .)) %>%
as_tibble()
txs
View(blockchair)
blockchair %>%
html_element(xpath = "/html/body/pre")
blockchair
library(tidyverse)
library(rvest)
# Reading "Blockchair Database Dumps" historic bitcoin transactions table:
blockchair <- read_html("https://gz.blockchair.com/bitcoin/transactions/")
# Selecting xpath of the transactions table:
txs <- blockchair %>%
html_element(xpath = "/html/body/pre") %>%
html_text() %>%
strsplit(" ") %>%
unlist() %>%
keep(grepl("-", .)) %>%
as_tibble()
txs
blockchair %>%
html_element(xpath = "/html/body/pre") %>%
html_text() %>%
strsplit(" ") %>%
unlist() %>%
keep(grepl("-", .)) %>%
as_tibble() %>%
transmute(date = as_date(value))
blockchair %>%
html_element(xpath = "/html/body/pre") %>%
html_text() %>%
strsplit(" ") %>%
unlist() %>%
keep(grepl("-", .)) %>%
as_tibble() %>%
transmute(date = as_date("value"))
blockchair %>%
html_element(xpath = "/html/body/pre") %>%
html_text() %>%
strsplit(" ") %>%
unlist() %>%
keep(grepl("-", .)) %>%
as_tibble() %>%
transmute(value = as_date("value"))
txs
# Selecting xpath of the transactions table:
txs <- blockchair %>%
html_element(xpath = "/html/body/pre") %>%
html_text() %>%
strsplit(" ") %>%
unlist() %>%
keep(grepl("-", .)) %>%
as_tibble() %>%
txs %>%  transmute(value = as_date(value))
# Selecting xpath of the transactions table:
txs <- blockchair %>%
html_element(xpath = "/html/body/pre") %>%
html_text() %>%
strsplit(" ") %>%
unlist() %>%
keep(grepl("-", .)) %>%
as_tibble() %>%
txs %>%
transmute(value = as_date(value))
txs %>%
transmute(value = as_date(value))
txs %>%
transmute(value = as.Date(value))
txs
txs %>% arrange(desc())
txs %>% arrange(desc(value))
?as_date
# Selecting xpath of the transactions table:
txs <- blockchair %>%
html_element(xpath = "/html/body/pre") %>%
html_text() %>%
strsplit(" ") %>%
unlist() %>%
keep(grepl("-", .)) %>%
as_tibble()
library(tidyverse)
library(rvest)
library(lubridate)
# Reading "Blockchair Database Dumps" historic bitcoin transactions table:
blockchair <- read_html("https://gz.blockchair.com/bitcoin/transactions/")
# Selecting xpath of the transactions table:
txs <- blockchair %>%
html_element(xpath = "/html/body/pre") %>%
html_text() %>%
strsplit(" ") %>%
unlist() %>%
keep(grepl("-", .)) %>%
as_tibble()
View(txs)
blockchair %>%
html_element(xpath = "/html/body/pre") %>%
html_text() %>%
strsplit(" ")
blockchair %>%
html_element(xpath = "/html/body/pre") %>%
html_text()
blockchair %>%
html_element(xpath = "/html/body/pre")
# Selecting xpath of the transactions table:
txs <- blockchair %>%
html_element(xpath = "/html/body/pre") %>%
html_text()
txs
# Using regex to extract date and the last number
date <- sub(".*\\s(\\d{2}-\\w{3}-\\d{4}).*", "\\1", txs)
date
date
# Using regex to extract date and the last number
dates <- sub(".*\\s(\\d{2}-\\w{3}-\\d{4}).*", "\\1", txs)
library(stringr)
# Selecting xpath of the transactions table:
txs <- blockchair %>%
html_element(xpath = "/html/body/pre") %>%
html_text()
# Using regex to extract date and the last number
dates <- str_extract(txs, "\\d{2}-\\w{3}-\\d{4}")
dates
blockchair %>%
html_element(xpath = "/html/body/pre") %>%
html_children()
# Selecting xpath of the transactions table:
tx_nodes <- blockchair %>%
html_element(xpath = "/html/body/pre") %>%
html_children()  # Split the node into individual lines
View(tx_nodes)
# Using regex to extract date and the last number for each line
dates <- str_extract(xml_text(tx_nodes), "\\d{2}-\\w{3}-\\d{4}")
?xml_text
library(xml2)
# Using regex to extract date and the last number for each line
dates <- str_extract(xml_text(tx_nodes), "\\d{2}-\\w{3}-\\d{4}")
dates
tx_nodes[2]
x=tx_nodes[2]
x
View(x)
xml_attrs(x[[1]])
# Reading "Blockchair Database Dumps" historic bitcoin transactions table:
blockchair <- read_html("https://gz.blockchair.com/bitcoin/transactions/")
# Selecting xpath of the transactions table:
tx_nodes <- blockchair %>%
html_nodes(xpath = "/html/body/pre/a")  # Selecting only the anchor nodes with dates
# Extracting dates and last numbers
dates <- tx_nodes %>%
html_text() %>%
str_extract("\\d{2}-\\w{3}-\\d{4}")
last_numbers <- tx_nodes %>%
html_text() %>%
str_extract("\\d+$")
dates
tx_nodes
# Reading "Blockchair Database Dumps" historic bitcoin transactions table:
blockchair <- read_html("https://gz.blockchair.com/bitcoin/transactions/")
# Selecting xpath of the transactions table:
tx_nodes <- blockchair %>%
html_nodes(xpath = "/html/body/pre")  # Selecting the pre element containing the text
# Extracting dates and last numbers
lines <- tx_nodes %>%
xml_text()
dates <- str_extract(lines, "\\d{2}-\\w{3}-\\d{4}")
last_numbers <- str_extract(lines, "\\d+$")
# Combine the extracted data into a data frame
extracted_data <- data.frame(date = dates, last_number = last_numbers)
extacted_data
extracted_data
# Selecting xpath of the transactions table:
tx_nodes <- blockchair %>%
html_nodes(xpath = "/html/body/pre")  # Selecting the pre element containing the text
# Extracting dates and last numbers
lines <- tx_nodes %>%
xml_text()
lines
# Selecting xpath of the transactions table:
tx_nodes <- blockchair %>%
html_element(xpath = "/html/body/pre") %>%
html_text()%>%
strsplit(" ")
tx_nodes
blockchair %>%
html_element(xpath = "/html/body/pre") %>%
html_text()%>%
# strsplit(" ")
strsplit(lines, "[[:space:]\r\n]+")
blockchair %>%
html_element(xpath = "/html/body/pre") %>%
html_text()%>%
strsplit("    ")
blockchair %>%
html_element(xpath = "/html/body/pre") %>%
html_text()%>%
# strsplit("    ")
strsplit(lines, "[[:space:]\r\n]+")
blockchair %>%
html_element(xpath = "/html/body/pre") %>%
html_text()%>%
# strsplit("    ")
strsplit("\n")
# Selecting xpath of the transactions table:
tx_nodes <- blockchair %>%
html_element(xpath = "/html/body/pre") %>%
html_text()%>%
strsplit("\n")
tx_nodes
# Function to extract date (without time) and number from each line
extract_info <- function(line) {
parts <- strsplit(line, "\\s+")[[1]]
date <- parts[2]
numeric_value <- as.numeric(sub("\\D", "", parts[3]))
return(data.frame(date = date, numeric_value = numeric_value))
}
# Extracting date (without time) and number from each line and combining them into a data frame
extracted_data <- do.call(rbind, lapply(lines[[1]], extract_info))
extracted_data
# Reading "Blockchair Database Dumps" historic bitcoin transactions table:
blockchair <- read_html("https://gz.blockchair.com/bitcoin/transactions/")
# Selecting xpath of the transactions table:
tx_nodes <- blockchair %>%
html_element(xpath = "/html/body/pre") %>%
html_text()%>%
strsplit("\n")
tx_nodes
class(tx_nodes)
# Selecting xpath of the transactions table:
txs_list <- blockchair %>%
html_element(xpath = "/html/body/pre") %>%
html_text()%>%
strsplit("\n")
txs_list
length(txs_list)
txs_list %>%   strsplit("    ")
